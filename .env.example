# ============================================
# Loop Gateway - Environment Configuration
# ============================================
# Copy this file to .env and adjust values

# --- Required ---
ANTHROPIC_API_KEY=sk-ant-xxxxx

# --- Server ---
PORT=3000
HOST=0.0.0.0

# --- Agent ---
# Model to use: claude-sonnet-4-20250514, claude-opus-4-20250514, claude-haiku-4-5-20251001
AGENT_MODEL=claude-sonnet-4-20250514
# Max tokens per agent response
AGENT_MAX_TOKENS=8192
# System prompt file path (inside container)
AGENT_SYSTEM_PROMPT_FILE=/data/system-prompt.md

# --- Hot-Swap Models (optional) ---
# Auto-switch models mid-conversation based on complexity.
# Starts with Haiku for fast answers, escalates to Opus for complex questions.
HOT_SWAP_ENABLED=false
# Allow de-escalation back to cheaper models for simple follow-ups
HOT_SWAP_DEESCALATION=true

# --- Fallback Chains (optional) ---
# Auto-failover to alternative providers when Claude is down.
# Claude → GPT-4o → Ollama (local). Zero downtime.
FALLBACK_ENABLED=false
# OpenAI API key for GPT-4o fallback
OPENAI_API_KEY=
# OpenAI model to use as fallback
FALLBACK_OPENAI_MODEL=gpt-4o
# Ollama URL for local model fallback
OLLAMA_URL=http://localhost:11434/v1
# Ollama model to use
FALLBACK_OLLAMA_MODEL=llama3

# --- Edge Deployment (optional) ---
# Lightweight mode for Raspberry Pi, VPS with 1GB RAM, IoT/Kiosk systems.
# Disables skills, containers, file watchers. Forces Haiku model.
EDGE_MODE=false
# Force Haiku-only in edge mode (default true when EDGE_MODE=true)
EDGE_HAIKU_ONLY=true
# Disable skills system in edge mode (default true when EDGE_MODE=true)
EDGE_DISABLE_SKILLS=true
# Max conversation history messages (lower = less memory)
EDGE_MAX_HISTORY=8
# Max tokens per response in edge mode
EDGE_MAX_TOKENS=4096
# Max concurrent requests in edge mode
EDGE_MAX_CONCURRENT=2

# --- Container Isolation (optional) ---
# Run each agent invocation in an isolated Docker container (nanoclaw pattern)
# Requires: docker build -t loop-gateway-agent:latest ./agent-runner
AGENT_CONTAINER_MODE=false
# Max concurrent containers (default 3)
MAX_CONCURRENT_CONTAINERS=3
# Container timeout in ms (default 600000 = 10 min)
CONTAINER_TIMEOUT_MS=600000

# --- Telegram (optional) ---
# Get a bot token from @BotFather on Telegram
TELEGRAM_BOT_TOKEN=
# Comma-separated list of allowed Telegram user IDs (leave empty to allow all)
TELEGRAM_ALLOWED_USERS=

# --- WhatsApp (optional) ---
# WhatsApp will show a QR code in the Web UI on first connect
WHATSAPP_ENABLED=false

# --- Email (optional) ---
EMAIL_IMAP_HOST=
EMAIL_IMAP_PORT=993
EMAIL_IMAP_USER=
EMAIL_IMAP_PASS=
EMAIL_SMTP_HOST=
EMAIL_SMTP_PORT=587
EMAIL_SMTP_USER=
EMAIL_SMTP_PASS=
EMAIL_POLL_INTERVAL_MS=30000
# Only process emails from these addresses (comma-separated, leave empty for all)
EMAIL_ALLOWED_SENDERS=

# --- CapCut API (optional) ---
# Local CapCutAPI server (https://github.com/sun-guannan/CapCutAPI)
# Requires: python capcut_server.py running, CapCut installed, FFmpeg
CAPCUT_API_HOST=http://localhost
CAPCUT_API_PORT=9001
